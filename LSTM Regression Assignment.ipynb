{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "699648d0",
   "metadata": {},
   "source": [
    "| Field | Details |\n",
    "|-------|---------|\n",
    "| **Name** | Pros Loung |\n",
    "| **Course** | AAI-530 Data Analystics and Internet of Things |\n",
    "| **Assignment** | 4.1 - LSTM Predictor Models |\n",
    "| **GitHub Repository** | https://github.com/ploung/AAI-530-IoT-Assignment-4.1.git |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcfada6",
   "metadata": {},
   "source": [
    "# Long Short Term Memory Networks for IoT Prediction\n",
    "\n",
    "RNNs and LSTM models are very popular neural network architectures when working with sequential data, since they both carry some \"memory\" of previous inputs when predicting the next output. In this assignment we will continue to work with the Household Electricity Consumption dataset and use an LSTM model to predict the Global Active Power (GAP) from a sequence of previous GAP readings. You will build one model following the directions in this notebook closely, then you will be asked to make changes to that original model and analyze the effects that they had on the model performance. You will also be asked to compare the performance of your LSTM model to the linear regression predictor that you built in last week's assignment.\n",
    "\n",
    "## General Assignment Instructions\n",
    "\n",
    "These instructions are included in every assignment, to remind you of the coding standards for the class. Feel free to delete this cell after reading it. \n",
    "\n",
    "One sign of mature code is conforming to a style guide. We recommend the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html). If you use a different style guide, please include a cell with a link. \n",
    "\n",
    "Your code should be relatively easy-to-read, sensibly commented, and clean. Writing code is a messy process, so please be sure to edit your final submission. Remove any cells that are not needed or parts of cells that contain unnecessary code. Remove inessential `import` statements and make sure that all such statements are moved into the designated cell. \n",
    "\n",
    "When you save your notebook as a pdf, make sure that all cell output is visible (even error messages) as this will aid your instructor in grading your work.\n",
    "\n",
    "Make use of non-code cells for written commentary. These cells should be grammatical and clearly written. In some of these cells you will have questions to answer. The questions will be marked by a \"Q:\" and will have a corresponding \"A:\" spot for you. *Make sure to answer every question marked with a `Q:` for full credit.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96422f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Setting seed for reproducibility\n",
    "np.random.seed(1234)  \n",
    "PYTHONHASHSEED = 0\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation\n",
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb722f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this cell to import additional libraries or define helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d897e4",
   "metadata": {},
   "source": [
    "## Load and prepare your data\n",
    "\n",
    "We'll once again be using the cleaned household electricity consumption data from the previous two assignments. I recommend saving your dataset by running df.to_csv(\"filename\") at the end of assignment 2 so that you don't have to re-do your cleaning steps. If you are not confident in your own cleaning steps, you may ask your instructor for a cleaned version of the data. You will not be graded on the cleaning steps in this assignment, but some functions may not work if you use the raw data.\n",
    "\n",
    "Unlike when using Linear Regression to make our predictions for Global Active Power (GAP), LSTM requires that we have a pre-trained model when our predictive software is shipped (the ability to iterate on the model after it's put into production is another question for another day). Thus, we will train the model on a segment of our data and then measure its performance on simulated streaming data another segment of the data. Our dataset is very large, so for speed's sake, we will limit ourselves to 1% of the entire dataset.\n",
    "\n",
    "**TODO: Import your data, select the a random 1% of the dataset, and then split it 80/20 into training and validation sets (the test split will come from the training data as part of the tensorflow LSTM model call). HINT: Think carefully about how you do your train/validation split--does it make sense to randomize the data?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db3cf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load your data into a pandas dataframe here\n",
    "try:\n",
    "    file_path = \"household_power_clean/household_power_clean.csv\"\n",
    "    df = pd.read_csv(file_path, delimiter=\",\")\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69ad4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9510533",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a7845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create your training and validation sets here\n",
    "\n",
    "#assign size for data subset\n",
    "subset_size = 1\n",
    "\n",
    "#take chronological data subset (not random for time series!)\n",
    "df = df.iloc[:, 3:11]  #select columns 3 to 10 (Global_intensity to Sub_metering_3)\n",
    "# For time series, we should sort by datetime first, then take chronological subset\n",
    "df = df.sort_values('Datetime').reset_index(drop=True)  # Sort chronologically\n",
    "subset_end = int(len(df) * subset_size)\n",
    "df = df.iloc[:subset_end]  # Take first 100% chronologically\n",
    "\n",
    "#split data subset 80/20 for train/validation CHRONOLOGICALLY\n",
    "split_index = int(len(df) * 0.8)\n",
    "train_df = df.iloc[:split_index]  # First 80% for training, select rows from the beginning to split_index\n",
    "val_df = df.iloc[split_index:]    # Last 20% for validation, select row starting at split_index to the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0a7b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset the indices for cleanliness\n",
    "train_df = train_df.reset_index()\n",
    "val_df = val_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d60b01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c78d0ab",
   "metadata": {},
   "source": [
    "## Normalize training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445b600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select sensor columns for normalization (from 0 to 1). \n",
    "#Global_active_power is the target variable and Datetime are not normalized.\n",
    "columns_to_normalize = ['Global_reactive_power', 'Voltage', 'Global_intensity', 'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "train_df_normalize = pd.DataFrame(scaler.fit_transform(\n",
    "    train_df[columns_to_normalize]), \n",
    "    columns=columns_to_normalize, \n",
    "    index=train_df.index)   \n",
    "\n",
    "#recombine normalized columns with unnormalized target and datetime columns\n",
    "join_df = train_df[['Datetime', 'Global_active_power']].join(train_df_normalize)\n",
    "train_df = join_df.sort_values('Datetime').reset_index(drop=True) #sort by datetime and reset index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411126b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0249d27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize validation data\n",
    "val_df_normalize = pd.DataFrame(scaler.transform(val_df[columns_to_normalize]), \n",
    "                                columns=columns_to_normalize, \n",
    "                                index=val_df.index)\n",
    "\n",
    "#recombine normalized columns with unnormalized target and datetime columns\n",
    "val_join_df = val_df[['Datetime', 'Global_active_power']].join(val_df_normalize)\n",
    "\n",
    "# Step 3: Sort by datetime and reset index (same as train_df)\n",
    "val_df = val_join_df.sort_values('Datetime').reset_index(drop=True)\n",
    "\n",
    "print(\"Validation data after preprocessing:\")\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a34258",
   "metadata": {},
   "source": [
    "Next we need to create our input and output sequences. In the lab session this week, we used an LSTM model to make a binary prediction, but LSTM models are very flexible in what they can output: we can also use them to predict a single real-numbered output (we can even use them to predict a sequence of outputs). Here we will train a model to predict a single real-numbered output such that we can compare our model directly to the linear regression model from last week.\n",
    "\n",
    "**TODO: Create a nested list structure for the training data, with a sequence of GAP measurements as the input and the GAP measurement at your predictive horizon as your expected output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807b5117",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_arrays = []\n",
    "seq_labs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b6475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll start out with a 30 minute input sequence and a 5 minute predictive horizon\n",
    "# we don't need to work in seconds this time, since we'll just use the indices instead of a unix timestamp\n",
    "seq_length = 30\n",
    "ph = 5\n",
    "\n",
    "feat_cols = ['Global_active_power']\n",
    "\n",
    "#create list of sequence length GAP readings\n",
    "for start in range(len(train_df) - seq_length - ph):\n",
    "    seq_arrays.append(train_df[feat_cols].iloc[start:start+seq_length].values) #get sequence of GAP readings\n",
    "    seq_labs.append(train_df['Global_active_power'].iloc[start+seq_length+ph]) #get GAP reading at predictive horizon\n",
    "\n",
    "#convert to numpy arrays and floats to appease keras/tensorflow        \n",
    "seq_arrays = np.array(seq_arrays, dtype = object).astype(np.float32)\n",
    "seq_labs = np.array(seq_labs, dtype = object).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5c2abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(seq_arrays.shape == (len(train_df)-seq_length-ph,seq_length, len(feat_cols)))\n",
    "assert(seq_labs.shape == (len(train_df)-seq_length-ph,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16c46a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "range(2, len(train_df) - seq_length - ph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb66dc2",
   "metadata": {},
   "source": [
    "**Q: What is the function of the assert statements in the above cell? Why do we use assertions in our code?**\n",
    "\n",
    "A: The assert function checks to see seq_arrays and seq_labs have the right shape; seq_arrays  shape is (16359, 30, 1) and seq_lab shap is (16359, ). It is important to have the right shape for feeding into the model. \n",
    "\n",
    "## Model Training\n",
    "\n",
    "We will begin with a model architecture very similar to the model we built in the lab session. We will have two LSTM layers, with 5 and 3 hidden units respectively, and we will apply dropout after each LSTM layer. However, we will use a LINEAR final layer and MSE for our loss function, since our output is continuous instead of binary.\n",
    "\n",
    "**TODO: Fill in all values marked with a ?? in the cell below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a57c132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to save model\n",
    "model_path = 'LSTM_model1.keras'\n",
    "\n",
    "# build the network\n",
    "nb_features = seq_arrays.shape[2] #number of features used as input\n",
    "nb_out = 1 #number of outputs\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#add first LSTM layer\n",
    "model.add(LSTM(\n",
    "         input_shape=(seq_length, nb_features),\n",
    "         units=5, #number of LSTM units\n",
    "         return_sequences=True))\n",
    "model.add(Dropout(0.2)) \n",
    "\n",
    "# add second LSTM layer\n",
    "model.add(LSTM(\n",
    "          units=3, #number of LSTM units\n",
    "          return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Dense(units=nb_out)) #number of output units\n",
    "model.add(Activation('linear')) #linear activation for regression for predicting continuous values\n",
    "optimizer = keras.optimizers.Adam(learning_rate = 0.01)\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer,metrics=['mse'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# fit the model with sequence arrays and labels\n",
    "history = model.fit(seq_arrays, seq_labs, epochs=100, batch_size=500, validation_split=0.05, verbose=2,\n",
    "          callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min'),\n",
    "                       keras.callbacks.ModelCheckpoint(model_path,monitor='val_loss', save_best_only=True, mode='min', verbose=0)]\n",
    "          )\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5dd990",
   "metadata": {},
   "source": [
    "We will use the code from the book to visualize our training progress and model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d4d9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for Loss/MSE\n",
    "fig_acc = plt.figure(figsize=(10, 10))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss/MSE')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "fig_acc.savefig(\"LSTM_loss1.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0522509",
   "metadata": {},
   "source": [
    "## Validating our model\n",
    "\n",
    "Now we need to create our simulated streaming validation set to test our model \"in production\". With our linear regression models, we were able to begin making predictions with only two datapoints, but the LSTM model requires an input sequence of *seq_length* to make a prediction. We can get around this limitation by \"padding\" our inputs when they are too short.\n",
    "\n",
    "**TODO: create a nested list structure for the validation data, with a sequence of GAP measurements as the input and the GAP measurement at your predictive horizon as your expected output. Begin your predictions after only two GAP measurements are available, and check out [this keras function](https://www.tensorflow.org/api_docs/python/tf/keras/utils/pad_sequences) to automatically pad sequences that are too short.**\n",
    "\n",
    "**Q: Describe the pad_sequences function and how it manages sequences of variable length. What does the \"padding\" argument determine, and which setting makes the most sense for our use case here?**\n",
    "\n",
    "A: The LSTM model expects input sequences of 30 consecutive datapoints and then predicts GAP value at the time defined by Prediction Horizon (PH). For validation, we only read in 2 consecutive datapoints, but the model expects 30 datapoints. We can address this issue by “padding” inputs when they are too short using **tf.keras.utils.pad_sequences** method with the following arguments:\n",
    "- Sequences\n",
    "- maxlen=30\n",
    "- padding='pre', \n",
    "- value=0.0\n",
    "\n",
    "padding=pre adds padding at the beginning of the input sequences, which is preferred for time series data and padded value = 0 (value=0.0). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823ea44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_arrays = [] #input sequences for validation data\n",
    "val_labs = [] #target predictions for validation data\n",
    "\n",
    "#create list of GAP readings starting with a minimum of two readings\n",
    "for seq_len in range(2, min(len(val_df), seq_length + 1)):\n",
    "    for start in range(len(val_df) - seq_len - ph):\n",
    "        val_arrays.append(val_df[feat_cols].iloc[start:start+seq_len].values) #get sequence of GAP readings\n",
    "        val_labs.append(val_df['Global_active_power'].iloc[start+seq_len+ph]) #get GAP reading at predictive horizon\n",
    "\n",
    "# use the pad_sequences function on your input sequences\n",
    "# remember that we will later want our datatype to be np.float32 \n",
    "val_arrays = keras.utils.pad_sequences(val_arrays, maxlen=seq_length, padding='pre', value=0.0) #pad with zeros at the beginning\n",
    "        \n",
    "#convert labels to numpy arrays and floats to appease keras/tensorflow\n",
    "val_labs = np.array(val_labs, dtype = object).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a553f881",
   "metadata": {},
   "source": [
    "We will now run this validation data through our LSTM model and visualize its performance like we did on the linear regression data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaf0946",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_test = model.evaluate(val_arrays, val_labs, verbose=2)\n",
    "print('\\nMSE: {}'.format(scores_test[1]))\n",
    "\n",
    "y_pred_test = model.predict(val_arrays)\n",
    "y_true_test = val_labs\n",
    "\n",
    "test_set = pd.DataFrame(y_pred_test)\n",
    "test_set.to_csv('submit_test.csv', index = None) #save predictions to csv file\n",
    "\n",
    "# Plot the predicted data vs. the actual data\n",
    "# we will limit our plot to the first 500 predictions for better visualization\n",
    "fig_verify = plt.figure(figsize=(10, 5))\n",
    "plt.plot(y_pred_test[-500:], label = 'Predicted Value')\n",
    "plt.plot(y_true_test[-500:], label = 'Actual Value')\n",
    "plt.title('Global Active Power Prediction - Last 500 Points', fontsize=22, fontweight='bold')\n",
    "plt.ylabel('value')\n",
    "plt.xlabel('row')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig_verify.savefig(\"model_regression_verify.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24922e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract MSE values from training history\n",
    "train_mse = history.history['mse']  # Training MSE per epoch\n",
    "val_mse = history.history['val_mse']  # Validation MSE per epoch\n",
    "\n",
    "# Plot MSE curves\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_mse, label='Training MSE', color='blue')\n",
    "plt.plot(val_mse, label='Validation MSE', color='red')\n",
    "plt.title('LSTM Model MSE Over Training Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print final MSE values\n",
    "print(f\"Final Training MSE: {train_mse[-1]:.4f}\")\n",
    "print(f\"Final Validation MSE: {val_mse[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f8b7be",
   "metadata": {},
   "source": [
    "Q: How did your model perform? What can you tell about the model from the loss curves? What could we do to try to improve the model?\n",
    "\n",
    "A: For train dataset, the model shows steady training MSE progress, starting MSE around 1.6 (epoch 0) and final MSE around 1.0995 (final epoch). And for validation dataset, MSE is consistently around 0.92 – 0.95 with a final value of around 0.9236, indicating stability throughout training. Stable validation loss indicting, indicating good generation, no overfitting, and the model successfully learned patterns from the data.  \n",
    "\n",
    "To improve the model, I am going to tune the following parameters:\n",
    "- Add more features to training and validation data.\n",
    "- Crete and add new time-based features to training and validation data.\n",
    "- Modify model capacity: add more LSTM units and layers, add regularization to Dense layer, and change Optimizer learning rate,\n",
    "- Change training strategies (epochs, batch size, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56c2def",
   "metadata": {},
   "source": [
    "## Model Optimization\n",
    "\n",
    "Now it's your turn to build an LSTM-based model in hopes of improving performance on this training set. Changes that you might consider include:\n",
    "\n",
    "- Add more variables to the input sequences\n",
    "- Change the optimizer and/or adjust the learning rate\n",
    "- Change the sequence length and/or the predictive horizon\n",
    "- Change the number of hidden layers in each of the LSTM layers\n",
    "- Change the model architecture altogether--think about adding convolutional layers, linear layers, - additional regularization, creating embeddings for the input data, changing the loss function, etc.\n",
    "\n",
    "There isn't any minimum performance increase or number of changes that need to be made, but I want to see that you have tried some different things. Remember that building and optimizing deep learning networks is an art and can be very difficult, so don't make yourself crazy trying to optimize for this assignment.\n",
    "\n",
    "**Q: What changes are you going to try with your model? Why do you think these changes could improve model performance?**\n",
    "\n",
    "A: To improve the model, I am going to tune the following parameters:\n",
    "- Add more features, feat_cols = ['Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity', 'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3' + other time-based features]\n",
    "- Increase model capacity:\n",
    "    - Add more LSTM units and layers.\n",
    "        - First LSTM layer, change units to 50.\n",
    "        - Second LSTM layer, change units to 25.\n",
    "        -  Dense layer, add regularization.\n",
    "        - Optimizer learning rate, reduce to slower learning rate 0.001)\n",
    "- Change training strategies (epochs, batch size, etc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50afded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# play with your ideas for optimization here\n",
    "\n",
    "#CREATE NEW FEATURES AND RECREATE SEQUENCE ARRAYS AND LABELS FOR TRAINING DATA\n",
    "# create and add time-based features such as hour of day, day of week, etc.\n",
    "train_df['hour'] = pd.to_datetime(train_df['Datetime']).dt.hour\n",
    "train_df['day_of_week'] = pd.to_datetime(train_df['Datetime']).dt.dayofweek\n",
    "\n",
    "#Convert time-based features to cyclical features\n",
    "train_df['hour_sin'] = np.sin(2 * np.pi * train_df['hour'] / 24)\n",
    "train_df['hour_cos'] = np.cos(2 * np.pi * train_df['hour'] / 24)\n",
    "train_df['day_sin'] = np.sin(2 * np.pi * train_df['day_of_week'] / 7)\n",
    "train_df['day_cos'] = np.cos(2 * np.pi * train_df['day_of_week'] / 7)\n",
    "\n",
    "#reset sequence arrays and labels, then recreate them with new features\n",
    "seq_arrays = []\n",
    "seq_labs = []\n",
    "seq_length = 30 # 30 minute input sequence\n",
    "ph = 5 # 5 minute predictive horizon\n",
    "\n",
    "#new feature columns with added time-based features\n",
    "feat_cols = ['Global_active_power', 'Global_reactive_power', 'Voltage', \n",
    "             'Global_intensity', 'Sub_metering_1', 'Sub_metering_2',\n",
    "             'Sub_metering_3', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos']\n",
    "\n",
    "#create list of sequence length GAP readings\n",
    "for start in range(len(train_df) - seq_length - ph):\n",
    "    seq_arrays.append(train_df[feat_cols].iloc[start:start+seq_length].values) #get sequence of GAP readings\n",
    "    seq_labs.append(train_df['Global_active_power'].iloc[start+seq_length+ph]) #get GAP reading at predictive horizon\n",
    "\n",
    "#convert to numpy arrays and floats to appease keras/tensorflow        \n",
    "seq_arrays = np.array(seq_arrays, dtype = object).astype(np.float32)\n",
    "seq_labs = np.array(seq_labs, dtype = object).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f485a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_arrays.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2deb140",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modify model architecture or hyperparameters:\n",
    "#Add more LSTM layers, change number of units, adjust dropout rates, change learning rate, etc.\n",
    "\n",
    "model_path = 'LSTM_model2.keras' #define path to save model\n",
    "\n",
    "# build the network\n",
    "nb_features = seq_arrays.shape[2] #number of features used as input\n",
    "nb_out = 1 #number of outputs\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#add first LSTM layer\n",
    "model.add(LSTM(\n",
    "         input_shape=(seq_length, nb_features),\n",
    "         units=50, #Changed number of LSTM units to 50\n",
    "         return_sequences=True))\n",
    "model.add(Dropout(0.2)) \n",
    "\n",
    "# add second LSTM layer\n",
    "model.add(LSTM(\n",
    "          units=25, #Changed number of LSTM units to 25\n",
    "          return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=nb_out, kernel_regularizer=keras.regularizers.l2(0.001))) #number of output units, added L2 regularization regularization\n",
    "model.add(Activation('linear')) #linear activation for regression for predicting continuous values\n",
    "optimizer = keras.optimizers.Adam(learning_rate = 0.001) #Changed learning rate to 0.001\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer,metrics=['mse'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# fit the model with sequence arrays and labels\n",
    "history = model.fit(seq_arrays, seq_labs,\n",
    "                    epochs=200, #increased epochs to 200\n",
    "                    batch_size=250, #smaller batch size\n",
    "                    validation_split=0.05, \n",
    "                    verbose=2,\n",
    "                    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min'),\n",
    "                       keras.callbacks.ModelCheckpoint(model_path,monitor='val_loss', save_best_only=True, mode='min', verbose=0)]\n",
    "          )\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27319b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE NEW FEATURES AND RECREATE SEQUENCE ARRAYS AND LABELS FOR VALIDATION DATA\n",
    "val_df['hour'] = pd.to_datetime(val_df['Datetime']).dt.hour\n",
    "val_df['day_of_week'] = pd.to_datetime(val_df['Datetime']).dt.dayofweek\n",
    "\n",
    "# Convert time-based features to cyclical features\n",
    "val_df['hour_sin'] = np.sin(2 * np.pi * val_df['hour'] / 24)\n",
    "val_df['hour_cos'] = np.cos(2 * np.pi * val_df['hour'] / 24)\n",
    "val_df['day_sin'] = np.sin(2 * np.pi * val_df['day_of_week'] / 7)\n",
    "val_df['day_cos'] = np.cos(2 * np.pi * val_df['day_of_week'] / 7)\n",
    "\n",
    "val_arrays = [] # input sequences for validation data\n",
    "val_labs = [] # target predictions for validation data\n",
    "\n",
    "# new feature columns with added time-based features\n",
    "feat_cols = ['Global_active_power', 'Global_reactive_power', 'Voltage', \n",
    "             'Global_intensity', 'Sub_metering_1', 'Sub_metering_2',\n",
    "             'Sub_metering_3', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos']\n",
    "\n",
    "# create list of GAP readings starting with a minimum of two readings\n",
    "for seq_len in range(2, min(len(val_df), seq_length + 1)):\n",
    "    for start in range(len(val_df) - seq_len - ph):\n",
    "        val_arrays.append(val_df[feat_cols].iloc[start:start+seq_len].values) # get sequence of GAP readings\n",
    "        val_labs.append(val_df['Global_active_power'].iloc[start+seq_len+ph]) # get GAP reading at predictive horizon\n",
    "\n",
    "# use the pad_sequences function on your input sequences\n",
    "# remember that we will later want our datatype to be np.float32 \n",
    "val_arrays = keras.utils.pad_sequences(val_arrays, maxlen=seq_length, padding='pre', value=0.0) # pad with zeros at the beginning\n",
    "        \n",
    "# convert labels to numpy arrays and floats to appease keras/tensorflow\n",
    "val_labs = np.array(val_labs, dtype = object).astype(np.float32)\n",
    "\n",
    "print(f\"Validation arrays shape: {val_arrays.shape}\")\n",
    "print(f\"Validation labels shape: {val_labs.shape}\")\n",
    "print(f\"Number of features: {val_arrays.shape[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1357112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show me how one or two of your different models perform \n",
    "# using the code from the \"Validating our model\" section above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0961ec",
   "metadata": {},
   "source": [
    "## Validate the optimized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be7eff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_test = model.evaluate(val_arrays, val_labs, verbose=2)\n",
    "print('\\nMSE: {}'.format(scores_test[1]))\n",
    "\n",
    "y_pred_test = model.predict(val_arrays)\n",
    "y_true_test = val_labs\n",
    "\n",
    "test_set = pd.DataFrame(y_pred_test)\n",
    "test_set.to_csv('submit_test.csv', index = None) #save predictions to csv file\n",
    "\n",
    "# Plot the predicted data vs. the actual data\n",
    "# we will limit our plot to the first 500 predictions for better visualization\n",
    "fig_verify = plt.figure(figsize=(10, 5))\n",
    "plt.plot(y_pred_test[-500:], label = 'Predicted Value')\n",
    "plt.plot(y_true_test[-500:], label = 'Actual Value')\n",
    "plt.title('Global Active Power Prediction - Last 500 Points', fontsize=22, fontweight='bold')\n",
    "plt.ylabel('value')\n",
    "plt.xlabel('row')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig_verify.savefig(\"model_regression_verify.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceec892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract MSE values from training history\n",
    "train_mse = history.history['mse']  # Training MSE per epoch\n",
    "val_mse = history.history['val_mse']  # Validation MSE per epoch\n",
    "\n",
    "# Plot MSE curves\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_mse, label='Training MSE', color='blue')\n",
    "plt.plot(val_mse, label='Validation MSE', color='red')\n",
    "plt.title('LSTM Model MSE Over Training Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print final MSE values\n",
    "print(f\"Final Training MSE: {train_mse[-1]:.4f}\")\n",
    "print(f\"Final Validation MSE: {val_mse[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ccb037",
   "metadata": {},
   "source": [
    "**Q: How did your model changes affect performance on the validation data? Why do you think they were/were not effective? If you were trying to optimize for production, what would you try next?**\n",
    "\n",
    "A: The optimized model shows significant improvement over the original model. The model demonstrates steady training MSE progress, starting around 1.2 at epoch 0 and achieving a final MSE of approximately 1.039 at the final epoch. For the validation dataset, the MSE consistently remains below 0.95 with a final value of around 0.9160, indicating good generalization, no overfitting, and successful pattern learning from the data.\n",
    "\n",
    "The improvements were effective due to several key changes:\n",
    "1. **Additional features**: Adding time-based features (hour_sin, hour_cos, day_sin, day_cos) and all power-related features helped the model capture temporal patterns and relationships between different power measurements.\n",
    "2. **Increased model capacity**: Using 50 and 25 LSTM units (vs. 5 and 3 originally) provided more learning capacity.\n",
    "3. **Better regularization**: L2 regularization in the Dense layer helped prevent overfitting.\n",
    "4. **Optimized training**: Lower learning rate (0.001) and adjusted batch size improved convergence.\n",
    "\n",
    "For production optimization, I would try:\n",
    "- Hyperparameter tuning using grid search or Bayesian optimization\n",
    "- Ensemble methods combining multiple models\n",
    "- Advanced architectures like attention mechanisms or transformer layers\n",
    "- Feature engineering based on domain expertise (seasonal patterns, weather data)\n",
    "\n",
    "**Q: How did the models that you built in this assignment compare to the linear regression model from last week? Think about model performance and other IoT device considerations; Which model would you choose to use in an IoT system that predicts GAP for a single household with a 5-minute predictive horizon, and why?**\n",
    "\n",
    "A: Comparison between LSTM and Linear Regression models:\n",
    "\n",
    "Linear Regression Performance Summary from Assignment 3.1:\n",
    "- Univariate model (Time only): MSE = 0.5804 (baseline)\n",
    "- Bivariate model (Time + Voltage): MSE = 0.5748 (+0.96% improvement)\n",
    "- Multivariate model (Time + Voltage + Global Intensity): MSE = 0.5457 (+5.97% improvement)\n",
    "\n",
    "LSTM Performance Summary:\n",
    "- Original LSTM model:\n",
    "  - Train MSE ~ 1.6 – 1.1\n",
    "  - Valid MSE ~ 0.9236 (final)\n",
    "- Optimized LSTM model:\n",
    "  - Train MSE ~ 1.2 – 1.0392\n",
    "  - Valid MSE ~ 0.9160 (final)\n",
    "\n",
    "Based on the results, linear regression model achieved significantly better MSE performance as compared to the LSTM model. The linear regression shows clear benefit from additional features, with Global Intensity providing the most substantial improvement (+5.97%).\n",
    "\n",
    "For an IoT system predicting GAP with a 5-minute horizon, I would choose the **Linear Regression model** because it achieved better accuracy and easy to implement:\n",
    "1. **Resource Constraints**: IoT devices typically have limited memory and processing power\n",
    "2. **Real-time Requirements**: 5-minute predictions need fast, reliable responses.\n",
    "3. **Energy Efficiency**: Lower power consumption is critical for battery-powered IoT devices.\n",
    "4. **Maintenance**: Simpler models are easier to deploy, monitor, and update in production.\n",
    "The LSTM model would be better suited for cloud-based analytics or edge computing scenarios where computational resources are less constrained. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
